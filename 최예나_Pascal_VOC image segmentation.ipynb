{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766d90bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.9/site-packages (1.14.0)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.9/site-packages (from datasets) (2021.11.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0,>=0.0.19 in /opt/conda/lib/python3.9/site-packages (from datasets) (0.0.19)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.9/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from datasets) (1.21.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets) (1.3.3)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.9/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets) (6.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets) (4.0.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets) (3.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->datasets) (3.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b977bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.9/site-packages (0.0.19)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from huggingface_hub) (4.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from huggingface_hub) (4.62.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.9/site-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from huggingface_hub) (3.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from huggingface_hub) (2.26.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.9->huggingface_hub) (3.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface_hub) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface_hub) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface_hub) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface_hub) (1.26.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ad7188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets \n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "899c9aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration nateraw___pascal-voc-2012-c68607404d4811ac\n",
      "Reusing dataset parquet (/aiffel/.cache/huggingface/datasets/parquet/nateraw___pascal-voc-2012-c68607404d4811ac/0.0.0/9296ce43568b20d72ff8ff8ecbc821a16b68e9b8b7058805ef11f06e035f911a)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"nateraw/pascal-voc-2012\", split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a53d41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['image', 'mask'],\n",
      "    num_rows: 2913\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e4ce962",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/2039889283.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mWCC\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWCC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mQuantConv2d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantConv2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from .WCC import WCC\n",
    "from .QuantConv2d import QuantConv2d\n",
    "\n",
    "\n",
    "def quantize_deeplabmobilev2(model, bit_w, bit_a):\n",
    "    first_conv = model.backbone.low_level_features[0][0]\n",
    "    last_layer = model.classifier.classifier[3]\n",
    "    quantize_module(model, bit_w, bit_a)\n",
    "    model.backbone.low_level_features[0][0] = first_conv\n",
    "    model.classifier.classifier[3] = last_layer\n",
    "\n",
    "\n",
    "def wavelet_deeplabmobilev2(model, levels, compress_rate, bit_w, bit_a):\n",
    "    first_conv = model.backbone.low_level_features[0][0]\n",
    "    last_layer = model.classifier.classifier[3]\n",
    "    wavelet_module(model, levels, compress_rate, bit_w, bit_a)\n",
    "    model.backbone.low_level_features[0][0] = first_conv\n",
    "    model.classifier.classifier[3] = last_layer\n",
    "\n",
    "\n",
    "def quantize_module(module, bit_w, bit_a):\n",
    "    new_module = module\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        new_module = QuantConv2d(module.in_channels,\n",
    "                                 module.out_channels,\n",
    "                                 module.kernel_size,\n",
    "                                 module.stride,\n",
    "                                 module.padding,\n",
    "                                 module.dilation,\n",
    "                                 module.groups,\n",
    "                                 module.bias is not None,\n",
    "                                 bit_w,\n",
    "                                 bit_a)\n",
    "        new_module.weight = module.weight\n",
    "        new_module.bias = module.bias\n",
    "    for name, child in module.named_children():\n",
    "        new_module.add_module(name, quantize_module(child, bit_w, bit_a))\n",
    "    return new_module\n",
    "\n",
    "\n",
    "def change_module_bits(module, bit_w, bit_a):\n",
    "    if isinstance(module, QuantConv2d) or isinstance(module, WCC):\n",
    "        module.change_bit(bit_w, bit_a)\n",
    "    else:\n",
    "        for name, child in module.named_children():\n",
    "            change_module_bits(child, bit_w, bit_a)\n",
    "\n",
    "\n",
    "def wavelet_module(module, levels, compress_rate, bit_w, bit_a):\n",
    "    new_module = module\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        if module.kernel_size[0] > 1:\n",
    "            new_module = QuantConv2d(module.in_channels,\n",
    "                                     module.out_channels,\n",
    "                                     module.kernel_size,\n",
    "                                     module.stride,\n",
    "                                     module.padding,\n",
    "                                     module.dilation,\n",
    "                                     module.groups,\n",
    "                                     module.bias is not None,\n",
    "                                     bit_w,\n",
    "                                     bit_a)\n",
    "            new_module.weight = module.weight\n",
    "            new_module.bias = module.bias\n",
    "        else:\n",
    "            new_module = WCC(module.in_channels,\n",
    "                             module.out_channels,\n",
    "                             module.stride[0],\n",
    "                             module.padding[0],\n",
    "                             module.dilation[0],\n",
    "                             module.groups,\n",
    "                             module.bias is not None,\n",
    "                             levels,\n",
    "                             compress_rate,\n",
    "                             bit_w,\n",
    "                             bit_a)\n",
    "            new_module.weight = nn.Parameter(module.weight.squeeze(-1))\n",
    "            new_module.bias = module.bias\n",
    "        if isinstance(module, QuantConv2d):\n",
    "            new_module.act_quant.a_alpha = module.act_quant.a_alpha\n",
    "            new_module.weight_quant.w_alpha = module.weight_quant.w_alpha\n",
    "    else:\n",
    "        for name, child in module.named_children():\n",
    "            new_module.add_module(name, wavelet_module(child, levels, compress_rate, bit_w, bit_a))\n",
    "    return new_module\n",
    "\n",
    "\n",
    "def change_module_wt_params(module, compress_rate, levels):\n",
    "    if isinstance(module, WCC):\n",
    "        module.change_wt_params(compress_rate, levels)\n",
    "    else:\n",
    "        for name, child in module.named_children():\n",
    "            change_module_wt_params(child, compress_rate, levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f5eb9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.9/site-packages (2.7.0)\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
      "     |████████████████████████████████| 5.5 MB 6.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.9/site-packages (from tensorboard) (0.12.0)\n",
      "Collecting protobuf>=3.19.6\n",
      "  Downloading protobuf-4.24.0-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n",
      "     |████████████████████████████████| 311 kB 59.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard) (1.21.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard) (2.3.3)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "     |████████████████████████████████| 6.6 MB 65.6 MB/s            \n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.57.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "     |████████████████████████████████| 5.3 MB 67.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard) (2.0.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.9/site-packages (from tensorboard) (0.37.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard) (59.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard) (3.3.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from absl-py>=0.4->tensorboard) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.8)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "     |████████████████████████████████| 181 kB 99.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.26.7)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard) (4.8.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.1.1)\n",
      "Installing collected packages: google-auth, tensorboard-data-server, protobuf, grpcio, google-auth-oauthlib, tensorboard\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.3.3\n",
      "    Uninstalling google-auth-2.3.3:\n",
      "      Successfully uninstalled google-auth-2.3.3\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.6.1\n",
      "    Uninstalling tensorboard-data-server-0.6.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.1\n",
      "    Uninstalling protobuf-3.19.1:\n",
      "      Successfully uninstalled protobuf-3.19.1\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.42.0\n",
      "    Uninstalling grpcio-1.42.0:\n",
      "      Successfully uninstalled grpcio-1.42.0\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.4.6\n",
      "    Uninstalling google-auth-oauthlib-0.4.6:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.7.0\n",
      "    Uninstalling tensorboard-2.7.0:\n",
      "      Successfully uninstalled tensorboard-2.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-metadata 1.5.0 requires protobuf<4,>=3.13, but you have protobuf 4.24.0 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.4 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.0.1 which is incompatible.\u001b[0m\n",
      "Successfully installed google-auth-2.22.0 google-auth-oauthlib-1.0.0 grpcio-1.57.0 protobuf-4.24.0 tensorboard-2.14.0 tensorboard-data-server-0.7.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce2d5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "719dc1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0807f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a89181e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "Traceback (most recent call last):\n",
       "  File \"/opt/conda/lib/python3.9/site-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
       "    from tensorboard.compat import notf  # noqa: F401\n",
       "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/opt/conda/lib/python3.9/site-packages/tensorboard/compat/__init__.py)\n",
       "\n",
       "During handling of the above exception, another exception occurred:\n",
       "\n",
       "Traceback (most recent call last):\n",
       "  File \"/opt/conda/bin/tensorboard\", line 8, in <module>\n",
       "    sys.exit(run_main())\n",
       "  File \"/opt/conda/lib/python3.9/site-packages/tensorboard/main.py\", line 39, in run_main\n",
       "    main_lib.global_init()\n",
       "  File \"/opt/conda/lib/python3.9/site-packages/tensorboard/main_lib.py\", line 40, in global_init\n",
       "    if getattr(tf, \"__version__\", \"stub\") == \"stub\":\n",
       "  File \"/opt/conda/lib/python3.9/site-packages/tensorboard/lazy.py\", line 65, in __getattr__\n",
       "    return getattr(load_once(self), attr_name)\n",
       "  File \"/opt/conda/lib/python3.9/site-packages/tensorboard/lazy.py\", line 97, in wrapper\n",
       "    cache[arg] = f(arg)\n",
       "  File \"/opt/conda/lib/python3.9/site-packages/tensorboard/lazy.py\", line 50, in load_once\n",
       "    module = load_fn()\n",
       "  File \"/opt/conda/lib/python3.9/site-packages/tensorboard/compat/__init__.py\", line 45, in tf\n",
       "    import tensorflow\n",
       "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/__init__.py\", line 41, in <module>\n",
       "    from tensorflow.python.tools import module_util as _module_util\n",
       "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/__init__.py\", line 40, in <module>\n",
       "    from tensorflow.python.eager import context\n",
       "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/context.py\", line 32, in <module>\n",
       "    from tensorflow.core.framework import function_pb2\n",
       "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/core/framework/function_pb2.py\", line 16, in <module>\n",
       "    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2\n",
       "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/core/framework/attr_value_pb2.py\", line 16, in <module>\n",
       "    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2\n",
       "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/core/framework/tensor_pb2.py\", line 16, in <module>\n",
       "    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\n",
       "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/core/framework/resource_handle_pb2.py\", line 16, in <module>\n",
       "    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n",
       "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/core/framework/tensor_shape_pb2.py\", line 36, in <module>\n",
       "    _descriptor.FieldDescriptor(\n",
       "  File \"/opt/conda/lib/python3.9/site-packages/google/protobuf/descriptor.py\", line 561, in __new__\n",
       "    _message.Message._CheckCalledFromGeneratedFile()\n",
       "TypeError: Descriptors cannot not be created directly.\n",
       "If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n",
       "If you cannot immediately regenerate your protos, some other possible workarounds are:\n",
       " 1. Downgrade the protobuf package to 3.20.x or lower.\n",
       " 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n",
       "\n",
       "More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36728e25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
